
## 📌 페이지 교체 알고리즘은 무엇이며, 왜 필요한가요?
페이지 교체 알고리즘은 물리 메모리에 빈 공간이 없을 때, <mark>새로운 페이지를 로드하기 위해 어떤 페이지를 제거할지 결정하는 방법</mark><mark> </mark>입니다. 이는 메모리 오버플로우를 방지하고 시스템 효율을 높이기 위해 필요합니다. 
##### 💡 주요 페이지 교체 알고리즘의 종류와 특징은 무엇인가요?

| **알고리즘** | **특징** | **장점** | **단점** |
| --- | --- | --- | --- |
| FIFO (First-In, First-Out) | 가장 먼저 들어온 페이지를 먼저 교체 | 구현이 가장 간단 | 벨라디의 이상 현상 발생 가능성 (프레임 증가 시 페이지 폴트 증가)  |
| OPT (Optimal) | 미래에 가장 오랫동안 사용되지 않을 페이지를 교체 | 가장 낮은 페이지 폴트율 달성 (최적) | 미래 예측이 불가능하여 실제 구현 어려움  |
| LRU (Least Recently Used) | 가장 오랫동안 사용되지 않은 페이지를 교체 | FIFO보다 효율적이며 벨라디의 이상 현상 발생 안함 | 구현 시 자료구조 복잡성 및 높은 비용 발생  |


운영체제의 핵심인 **페이지 교체 알고리즘**을 깊이 있게 다루며, 시스템 성능을 최적화하는 방법을 제시합니다. **FIFO, OPT, LRU**와 같은 주요 알고리즘들의 작동 원리와 장단점을 명확히 비교하여, 각 알고리즘이 페이지 폴트 발생률에 미치는 영향을 구체적인 예시로 설명합니다. 특히, LRU 알고리즘의 **실용적 구현 방안**과 하드웨어 지원의 중요성을 강조하며, 실제 시스템 설계 시 고려해야 할 **프레임 할당 문제**와 **스레싱 현상**의 해결책까지 제시하여 운영체제 지식을 실제 문제 해결에 적용할 수 있는 통찰을 제공합니다.
## 1. 페이지 교체 알고리즘의 필요성 및 개념 
![image](https://resource-release.s3.ap-northeast-2.amazonaws.com/thumbnails/pzidDMimvg8/2.jpg)
1. **페이지 교체 알고리즘의 등장 배경** 
  1. **메모리 오버로케이팅 문제**: 멀티 프로그래밍의 정도(Degree of Multiprogramming)를 높여 메모리에 동시에 로드되는 프로세스 수가 증가하면, 물리 메모리가 부족해지는 '메모리 오버로케이팅'이 발생할 수 있다. 
  - **예시**: 40개의 페이지 프레임이 있는 메모리에 6개의 프로세스가 각각 10개의 페이지를 가지고 있다면 총 60개의 페이지가 존재한다. 만약 각 프로세스가 5개의 페이지만 필요하다면 30개 프레임으로 충분하지만, 모든 페이지를 사용해야 하는 상황이 오면 문제가 발생한다. 
  2. **페이지 폴트 발생 시 빈 공간 부족**: 프로세스가 참조하려는 페이지가 메모리에 없어 페이지 폴트가 발생하고, 해당 페이지를 스왑인(Swap-in)하려 할 때 물리 메모리에 빈 프레임이 없는 경우가 생긴다. 
  3. **페이지 교체 알고리즘의 역할**: 빈 프레임이 없을 때, 현재 메모리에 있는 페이지 중 어떤 페이지를 스왑아웃(Swap-out)하여 새로운 페이지를 위한 공간을 확보할지 결정하는 것이 **페이지 교체 알고리즘(Page Replacement Algorithm)**이다. 

2. **페이지 폴트 서비스 과정에 페이지 교체 알고리즘 적용** 
  1. **프리 프레임 확인**: 페이지 폴트 발생 시, 먼저 디스크에서 원하는 페이지의 위치를 확인하고 물리 메모리에 빈 프레임(Free Frame)이 있는지 찾는다. 
  2. **페이지 교체 알고리즘 적용**: 빈 프레임이 없다면 페이지 교체 알고리즘(PR 알고리즘)을 적용하여 희생자(Victim) 프레임을 선정한다. 
  3. **페이지 스왑**: 선정된 희생자 페이지를 스왑아웃하고, 새로운 페이지를 스왑인하여 페이지 테이블을 업데이트한다. 
  4. **프로세스 재진입**: 페이지 폴트 처리가 완료되면 프로세스가 다시 실행되도록 한다. 

3. **페이지 교체 알고리즘의 두 가지 주요 문제** 
  1. **희생자 페이지 선정**: 어떤 페이지를 희생자로 선택해야 시스템 효율이 좋아질 것인가? 
  2. **프레임 할당**: 어떤 프로세스에 몇 개의 프레임을 할당해 주는 것이 효율적인가? 
  - 이 두 가지 문제 중 페이지 교체 알고리즘이 더 중요하게 다루어진다. 

4. **페이지 교체 알고리즘의 중요성**: 하드 디스크 접근(I/O)은 시간이 오래 걸리므로, 페이지 교체 알고리즘의 성능을 조금만 개선해도 시스템 전체의 효율이 크게 높아진다. 


## 2. 페이지 교체 알고리즘 평가 기준 및 FIFO 알고리즘 
![image]()
1. **평가 기준: 페이지 폴트율 최소화** 
  1. **목표**: 페이지 폴트율을 낮추는 것이 페이지 교체 알고리즘의 주된 목표이다. 
  2. **레퍼런스 스트링(Reference String)**: 알고리즘의 성능을 평가하기 위해 메모리 참조를 페이지 번호 단위로 나열한 문자열을 사용한다. 
  3. **평가 방법**: 레퍼런스 스트링을 사용하여 페이지 폴트의 개수를 세고, 이를 최소화할 수 있는 알고리즘을 설계하는 것이 목표이다. 

2. **페이지 프레임 개수와 페이지 폴트의 관계** 
  1. **일반적인 경향**: 프레임의 개수가 많을수록 페이지 폴트는 적어진다. 
  2. **이상적인 경우**: 물리 메모리 프레임이 논리 주소 공간의 모든 페이지를 수용할 만큼 충분히 많다면, 페이지 폴트는 거의 발생하지 않는다. 
  3. **현실적인 제약**: 실제 시스템에서는 프레임 개수가 제한적이므로, 적은 프레임 개수로 효율적인 알고리즘을 사용하는 것이 중요하다. 

3. **FIFO (First-In, First-Out) 페이지 교체 알고리즘** 
  1. **개념**: 가장 먼저 메모리에 들어온 페이지를 가장 먼저 교체하는 방식이다. 
  - **작동 원리**: 메모리에 빈 프레임이 없을 때, 가장 오래된(Oldest) 페이지를 희생자로 선정하여 교체한다. 
  2. **예시 (3개 프레임 기준)** 
  - **레퍼런스 스트링**: 7, 0, 1, 2, 0, 3, 0, 4, 2, 3, 0, 3, 2, 1, 2, 0, 1, 7, 0, 1
  - **초기 상태**: 모든 프레임이 비어 있다. 
  - **7, 0, 1**: 순서대로 프레임에 들어간다. (페이지 폴트 3회) 
  - **2 도착**: 7이 가장 먼저 들어왔으므로 7을 교체하고 2가 들어간다. (페이지 폴트 1회) 
  - **0 도착**: 0은 이미 메모리에 있으므로 페이지 폴트가 아니다. 
  - **3 도착**: 0이 가장 먼저 들어왔으므로 0을 교체하고 3이 들어간다. (페이지 폴트 1회) 
  - **0 도착**: 2가 가장 먼저 들어왔으므로 2를 교체하고 0이 들어간다. (페이지 폴트 1회) 
  - **이후 과정**: 동일한 방식으로 진행하여 총 15번의 페이지 폴트가 발생한다. 
  3. **장점**: 구현이 매우 간단하고 쉽다. 
  4. **단점: 벨라디의 이상 현상(Belady's Anomaly)** 
  - **현상**: 프레임의 개수를 증가시켰는데도 불구하고 오히려 페이지 폴트율이 증가하는 비정상적인 현상이다. 
  - **일반적인 상식과 반대**: 일반적으로 프레임이 많아질수록 페이지 폴트가 줄어들어야 한다. 
  - **예시**: 특정 레퍼런스 스트링에 FIFO를 적용했을 때, 프레임이 1개일 때 12회, 2개일 때 12회, 3개일 때 9회, 4개일 때 10회로, 프레임이 3개에서 4개로 늘어났을 때 페이지 폴트가 다시 증가하는 현상이 발생한다. 


## 3. OPT (Optimal) 및 LRU (Least Recently Used) 알고리즘 
![image]()
1. **OPT (Optimal) 페이지 교체 알고리즘** 
  1. **개념**: 앞으로 가장 오랫동안 사용되지 않을 페이지를 교체하는 최적의 알고리즘이다. 
  - **목표**: 가장 낮은 페이지 폴트율을 달성한다. 
  - **벨라디의 이상 현상 회피**: OPT 알고리즘은 벨라디의 이상 현상을 겪지 않는다. 
  2. **예시 (3개 프레임 기준)** 
  - **레퍼런스 스트링**: 7, 0, 1, 2, 0, 3, 0, 4, 2, 3, 0, 3, 2, 1, 2, 0, 1, 7, 0, 1
  - **7, 0, 1**: 순서대로 프레임에 들어간다. (페이지 폴트 3회) 
  - **2 도착**: 7, 0, 1 중 앞으로 가장 오랫동안 사용되지 않을 페이지는 7이므로 7을 교체하고 2가 들어간다. (페이지 폴트 1회) 
  - **0 도착**: 0은 이미 메모리에 있으므로 페이지 폴트가 아니다. 
  - **3 도착**: 2, 0, 1 중 앞으로 가장 오랫동안 사용되지 않을 페이지는 1이므로 1을 교체하고 3이 들어간다. (페이지 폴트 1회) 
  - **이후 과정**: 동일한 방식으로 진행하여 총 9번의 페이지 폴트가 발생한다. 
  - FIFO의 15회보다 훨씬 적은 수치이다. 
  3. **문제점**: 미래를 예측해야 하므로 **미래 지식(Future Knowledge)**이 필요하다. 
  - 실제 시스템에서는 구현이 불가능하다. 
  4. **활용**: 다른 페이지 교체 알고리즘의 성능을 평가하는 벤치마크(Benchmark) 용도로 사용된다. 
  - CPU 스케줄링의 SJF(Shortest Job First)와 유사한 개념이다. 

2. **LRU (Least Recently Used) 페이지 교체 알고리즘** 
  1. **개념**: 가장 오랫동안 사용되지 않은 페이지를 교체하는 알고리즘이다. 
  - **합리적 근거**: 과거에 오랫동안 사용되지 않은 페이지는 미래에도 사용되지 않을 가능성이 높다는 **지역성(Locality of Reference)** 원리에 기반한다. 
  - **벨라디의 이상 현상 회피**: OPT와 마찬가지로 벨라디의 이상 현상을 겪지 않는다. 
  2. **예시 (3개 프레임 기준)** 
  - **레퍼런스 스트링**: 7, 0, 1, 2, 0, 3, 0, 4, 2, 3, 0, 3, 2, 1, 2, 0, 1, 7, 0, 1
  - **7, 0, 1**: 순서대로 프레임에 들어간다. (페이지 폴트 3회) 
  - **2 도착**: 7, 0, 1 중 가장 오랫동안 참조되지 않은 페이지는 7이므로 7을 교체하고 2가 들어간다. (페이지 폴트 1회) 
  - **0 도착**: 0은 이미 메모리에 있으므로 페이지 폴트가 아니다. 
  - **3 도착**: 2, 0, 1 중 가장 오랫동안 참조되지 않은 페이지는 1이므로 1을 교체하고 3이 들어간다. (페이지 폴트 1회) 
  - **이후 과정**: 동일한 방식으로 진행하여 총 12번의 페이지 폴트가 발생한다. 
  - OPT(9회)보다는 많지만 FIFO(15회)보다는 적은 수치이다. 
  3. **장점**: 성능이 좋고 자주 사용되는 알고리즘이다. 
  4. **단점**: 구현이 복잡하고 비용이 많이 든다. 
  - 각 페이지가 마지막으로 사용된 시간을 기록해야 하므로, 자료 구조가 복잡해지고 메모리 용량을 많이 차지하며 계산 시간이 오래 걸릴 수 있다. 
  - 하드웨어 지원(카운터, 스택 등)이 필요하지만, 이를 받기 쉽지 않다. 


## 4. LRU 구현 방안 및 프레임 할당 문제 
![image]()
1. **LRU 구현 방안** 
  1. **카운터(Counter) 방식**:
  - **원리**: 각 페이지가 참조될 때마다 카운터를 증가시키거나 시스템 클럭 값을 기록한다. 
  - **희생자 선정**: 카운터 값이 가장 작거나 클럭 값이 가장 오래된 페이지를 희생자로 선정한다. 
  2. **스택(Stack) 방식**:
  - **원리**: 페이지가 참조될 때마다 해당 페이지 번호를 스택의 맨 위로 올린다. 
  - **희생자 선정**: 스택의 맨 아래에 있는 페이지가 가장 오랫동안 사용되지 않은 페이지이므로 이를 희생자로 선정한다. 
  - **구현의 어려움**: 스택의 중간에 있는 요소를 빼내고 다시 쌓는 과정이 필요하여 이중 연결 리스트(Doubly Linked List) 등으로 구현해야 한다. 
  3. **하드웨어 지원: 참조 비트(Reference Bit)** 
  - **필요성**: LRU를 소프트웨어로 구현하는 것은 비용이 많이 들고 어렵기 때문에 하드웨어 지원이 필요하다. 
  - **원리**: 각 페이지마다 '참조 비트'를 할당하여 초기에는 0으로 설정하고, 페이지가 참조될 때마다 1로 설정한다. 페이지가 교체되면 다시 0으로 리셋한다. 
  - **희생자 선정**: 참조 비트가 0인 페이지 중에서 희생자를 선택한다. 
  - **세컨드 찬스(Second Chance) 알고리즘**: FIFO 알고리즘에 참조 비트를 추가하여 LRU를 근사(Approximation)하는 방식이다. 
  - **작동 방식**: FIFO 방식으로 페이지를 교체하려 할 때, 해당 페이지의 참조 비트가 0이면 바로 교체한다. 만약 참조 비트가 1이면, 참조 비트를 0으로 바꾸고 해당 페이지에 '두 번째 기회'를 주어 다음 순서로 넘긴다. 
  - **원형 큐(Circular Queue) 활용**: 원형 큐를 이용하여 한 바퀴를 돌고 다시 돌아왔을 때 참조 비트가 0으로 초기화된 페이지를 희생자로 선정한다. 
  - **결론**: 참조 비트를 이용한 방식은 LRU를 완벽하게 구현하는 것은 아니지만, 효율적으로 LRU를 근사하는 방법이다. 

2. **프레임 할당(Frame Allocation) 문제** 
  1. **개념**: 여러 프로세스가 존재할 때, 각 프로세스에 물리 메모리의 프레임을 몇 개씩 할당할 것인가에 대한 문제이다. 
  - **예시**: 93개의 유저 프레임이 있고, 두 개의 프로세스(하나는 128페이지, 다른 하나는 256페이지)가 각각 80개, 92개의 페이지를 사용하려 할 때, 어떤 프로세스에 더 많은 프레임을 할당할 것인지 고민해야 한다. 
  2. **프레임 할당 전략** 
  - **균등 할당(Equal Allocation)**: 모든 프로세스에 동일한 수의 프레임을 할당하는 방식이다. 
  - **문제점**: 작은 프로세스는 효율적으로 돌아가지만, 큰 프로세스는 페이지 폴트가 자주 발생하여 비효율적일 수 있다. 
  - **비례 할당(Proportional Allocation)**: 프로세스의 크기(필요한 페이지 수)에 비례하여 프레임을 할당하는 방식이다. 
  - **장점**: 프로세스의 요구에 맞춰 프레임을 할당하여 효율성을 높일 수 있다. 
  - **교체 범위 결정**:
  - **지역 교체(Local Replacement)**: 페이지 폴트가 발생한 프로세스 자신의 프레임 내에서만 희생자를 선정하여 교체하는 방식이다. 
  - **전역 교체(Global Replacement)**: 시스템 전체의 모든 프레임 중에서 희생자를 선정하여 교체하는 방식이다. 
  - **결론**: 어떤 전략이 더 효율적인지는 시스템의 특성과 요구사항에 따라 달라진다. 


## 5. 스레싱(Thrashing) 현상 및 워킹 셋(Working Set) 모델 
![image]()
1. **스레싱(Thrashing) 현상** 
  1. **개념**: 프로세스가 페이지 인/아웃 작업에 너무 바빠서 실제 작업을 거의 수행하지 못하는 현상이다. 
  2. **발생 원인**:
  - **높은 멀티 프로그래밍 정도(Degree of Multiprogramming)**: 시스템에 너무 많은 프로세스나 스레드가 동시에 실행될 때 발생한다. 
  - **프레임 부족**: 각 프로세스에 할당되는 프레임 수가 너무 적어 페이지 폴트가 빈번하게 발생한다. 
  3. **CPU 사용량 그래프**: 멀티 프로그래밍 정도가 증가할수록 CPU 사용량은 증가하다가, 특정 지점을 넘어서면 급격히 감소한다. 
  - **원인**: CPU가 작업을 하려 해도 페이지 폴트가 계속 발생하여 프로세스가 대기 큐(Wait Queue)로 이동하고, CPU는 유휴 상태가 되기 때문이다. 
  - **결과**: CPU는 놀고 있지만 시스템은 버벅거리는 현상이 발생한다. 
  4. **진단**: CPU 사용률은 낮지만 메모리 사용률이 높고 시스템이 느려지는 경우 스레싱이 발생했다고 볼 수 있다. 

2. **워킹 셋(Working Set) 모델을 통한 스레싱 해결** 
  1. **기본 가정**: 메모리 참조에는 **지역성(Locality of Reference)**이 존재한다. 
  - **관찰**: 프로세스는 특정 시간 동안 특정 페이지들을 집중적으로 참조하며, 이 페이지들은 종종 인접해 있다. 
  2. **워킹 셋 윈도우(Working Set Window)**:
  - **개념**: 특정 시간 간격(델타, $\Delta$) 동안 프로세스가 활발하게 참조하는 페이지들의 집합을 '워킹 셋'이라고 한다. 
  - **슬라이딩 윈도우**: 이 윈도우를 시간 흐름에 따라 이동시키면서 워킹 셋을 관리한다. 
  3. **스레싱 문제 완화**:
  - **원리**: 워킹 셋에 속하는 페이지들은 항상 메모리에 로딩되도록 보장하고, 워킹 셋 바깥에 있는 페이지들을 희생자로 선정한다. 
  - **효과**: 프로세스가 필요로 하는 페이지들을 메모리에 유지함으로써 페이지 폴트 발생률을 줄이고, 스레싱 문제를 완화할 수 있다. 
  4. **활용**: 워킹 셋 모델은 스레싱 현상을 이해하고 관리하는 데 중요한 개념이다. 


## 6. 결론 및 학습 권장 사항 
![image](https://resource-release.s3.ap-northeast-2.amazonaws.com/thumbnails/pzidDMimvg8/2445.jpg)
1. **주요 페이지 교체 알고리즘 요약** 
  - **FIFO (First-In, First-Out)**: 가장 간단하지만 벨라디의 이상 현상 발생 가능성이 있다. 
  - **OPT (Optimal)**: 이론적으로 최적의 성능을 보이지만, 미래 예측이 불가능하여 실제 구현은 어렵다. 
  - **LRU (Least Recently Used)**: 실제 시스템에서 가장 많이 사용되며, 지역성 원리에 기반하여 효율적이다. 
  - **LRU 근사(Approximation)**: 참조 비트와 세컨드 찬스 알고리즘 등을 통해 LRU의 효율을 근사하여 구현한다. 

2. **학습 권장 사항**: OPT와 LRU 알고리즘의 개념을 꼼꼼히 살펴보고, 특히 LRU는 직접 문제를 풀어보며 이해도를 높이는 것이 중요하다. 

